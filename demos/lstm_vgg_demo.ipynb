{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    " # Table of Contents\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\" id=\"toc-level0\"><li><span><a href=\"http://localhost:8888/notebooks/Documents/git/vqa/demos/lstm_vgg_demo.ipynb#VGG16-model\" data-toc-modified-id=\"VGG16-model-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>VGG16 model</a></span><ul class=\"toc-item\"><li><span><a href=\"http://localhost:8888/notebooks/Documents/git/vqa/demos/lstm_vgg_demo.ipynb#Embedding-of-COCO-images\" data-toc-modified-id=\"Embedding-of-COCO-images-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Embedding of COCO images</a></span></li></ul></li><li><span><a href=\"http://localhost:8888/notebooks/Documents/git/vqa/demos/lstm_vgg_demo.ipynb#LSTM-+-VGG\" data-toc-modified-id=\"LSTM-+-VGG-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>LSTM + VGG</a></span><ul class=\"toc-item\"><li><span><a href=\"http://localhost:8888/notebooks/Documents/git/vqa/demos/lstm_vgg_demo.ipynb#Prepare-text-data\" data-toc-modified-id=\"Prepare-text-data-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Prepare text data</a></span></li><li><span><a href=\"http://localhost:8888/notebooks/Documents/git/vqa/demos/lstm_vgg_demo.ipynb#Prepare-image-data\" data-toc-modified-id=\"Prepare-image-data-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Prepare image data</a></span></li><li><span><a href=\"http://localhost:8888/notebooks/Documents/git/vqa/demos/lstm_vgg_demo.ipynb#Model-definition\" data-toc-modified-id=\"Model-definition-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Model definition</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add the path of the main directory\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import skimage.io as io\n",
    "import numpy as np\n",
    "import random\n",
    "import keras\n",
    "\n",
    "from keras.layers import Dense, Dropout, LSTM, multiply\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.utils import plot_model\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from vqa_api.PythonHelperTools.vqaTools.vqa import VQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from tools import img_dir, img_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# VGG16 model\n",
    "vgg_model = keras.applications.vgg16.VGG16(include_top=True, weights='imagenet', \n",
    "                               input_tensor=None, input_shape=None, \n",
    "                               pooling=None, classes=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Layer 1 \n",
      "\n",
      "{'dtype': 'float32', 'batch_input_shape': (None, 224, 224, 3), 'name': 'input_1', 'sparse': False} \n",
      "\n",
      "--> Layer 2 \n",
      "\n",
      "{'padding': 'same', 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'distribution': 'uniform', 'scale': 1.0, 'seed': None, 'mode': 'fan_avg'}}, 'name': 'block1_conv1', 'bias_regularizer': None, 'filters': 64, 'bias_constraint': None, 'activation': 'relu', 'trainable': True, 'data_format': 'channels_last', 'kernel_constraint': None, 'strides': (1, 1), 'dilation_rate': (1, 1), 'kernel_regularizer': None, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'use_bias': True, 'activity_regularizer': None, 'kernel_size': (3, 3)} \n",
      "\n",
      "--> Layer 3 \n",
      "\n",
      "{'padding': 'same', 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'distribution': 'uniform', 'scale': 1.0, 'seed': None, 'mode': 'fan_avg'}}, 'name': 'block1_conv2', 'bias_regularizer': None, 'filters': 64, 'bias_constraint': None, 'activation': 'relu', 'trainable': True, 'data_format': 'channels_last', 'kernel_constraint': None, 'strides': (1, 1), 'dilation_rate': (1, 1), 'kernel_regularizer': None, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'use_bias': True, 'activity_regularizer': None, 'kernel_size': (3, 3)} \n",
      "\n",
      "--> Layer 4 \n",
      "\n",
      "{'name': 'block1_pool', 'trainable': True, 'data_format': 'channels_last', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2)} \n",
      "\n",
      "--> Layer 5 \n",
      "\n",
      "{'padding': 'same', 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'distribution': 'uniform', 'scale': 1.0, 'seed': None, 'mode': 'fan_avg'}}, 'name': 'block2_conv1', 'bias_regularizer': None, 'filters': 128, 'bias_constraint': None, 'activation': 'relu', 'trainable': True, 'data_format': 'channels_last', 'kernel_constraint': None, 'strides': (1, 1), 'dilation_rate': (1, 1), 'kernel_regularizer': None, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'use_bias': True, 'activity_regularizer': None, 'kernel_size': (3, 3)} \n",
      "\n",
      "--> Layer 6 \n",
      "\n",
      "{'padding': 'same', 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'distribution': 'uniform', 'scale': 1.0, 'seed': None, 'mode': 'fan_avg'}}, 'name': 'block2_conv2', 'bias_regularizer': None, 'filters': 128, 'bias_constraint': None, 'activation': 'relu', 'trainable': True, 'data_format': 'channels_last', 'kernel_constraint': None, 'strides': (1, 1), 'dilation_rate': (1, 1), 'kernel_regularizer': None, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'use_bias': True, 'activity_regularizer': None, 'kernel_size': (3, 3)} \n",
      "\n",
      "--> Layer 7 \n",
      "\n",
      "{'name': 'block2_pool', 'trainable': True, 'data_format': 'channels_last', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2)} \n",
      "\n",
      "--> Layer 8 \n",
      "\n",
      "{'padding': 'same', 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'distribution': 'uniform', 'scale': 1.0, 'seed': None, 'mode': 'fan_avg'}}, 'name': 'block3_conv1', 'bias_regularizer': None, 'filters': 256, 'bias_constraint': None, 'activation': 'relu', 'trainable': True, 'data_format': 'channels_last', 'kernel_constraint': None, 'strides': (1, 1), 'dilation_rate': (1, 1), 'kernel_regularizer': None, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'use_bias': True, 'activity_regularizer': None, 'kernel_size': (3, 3)} \n",
      "\n",
      "--> Layer 9 \n",
      "\n",
      "{'padding': 'same', 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'distribution': 'uniform', 'scale': 1.0, 'seed': None, 'mode': 'fan_avg'}}, 'name': 'block3_conv2', 'bias_regularizer': None, 'filters': 256, 'bias_constraint': None, 'activation': 'relu', 'trainable': True, 'data_format': 'channels_last', 'kernel_constraint': None, 'strides': (1, 1), 'dilation_rate': (1, 1), 'kernel_regularizer': None, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'use_bias': True, 'activity_regularizer': None, 'kernel_size': (3, 3)} \n",
      "\n",
      "--> Layer 10 \n",
      "\n",
      "{'padding': 'same', 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'distribution': 'uniform', 'scale': 1.0, 'seed': None, 'mode': 'fan_avg'}}, 'name': 'block3_conv3', 'bias_regularizer': None, 'filters': 256, 'bias_constraint': None, 'activation': 'relu', 'trainable': True, 'data_format': 'channels_last', 'kernel_constraint': None, 'strides': (1, 1), 'dilation_rate': (1, 1), 'kernel_regularizer': None, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'use_bias': True, 'activity_regularizer': None, 'kernel_size': (3, 3)} \n",
      "\n",
      "--> Layer 11 \n",
      "\n",
      "{'name': 'block3_pool', 'trainable': True, 'data_format': 'channels_last', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2)} \n",
      "\n",
      "--> Layer 12 \n",
      "\n",
      "{'padding': 'same', 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'distribution': 'uniform', 'scale': 1.0, 'seed': None, 'mode': 'fan_avg'}}, 'name': 'block4_conv1', 'bias_regularizer': None, 'filters': 512, 'bias_constraint': None, 'activation': 'relu', 'trainable': True, 'data_format': 'channels_last', 'kernel_constraint': None, 'strides': (1, 1), 'dilation_rate': (1, 1), 'kernel_regularizer': None, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'use_bias': True, 'activity_regularizer': None, 'kernel_size': (3, 3)} \n",
      "\n",
      "--> Layer 13 \n",
      "\n",
      "{'padding': 'same', 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'distribution': 'uniform', 'scale': 1.0, 'seed': None, 'mode': 'fan_avg'}}, 'name': 'block4_conv2', 'bias_regularizer': None, 'filters': 512, 'bias_constraint': None, 'activation': 'relu', 'trainable': True, 'data_format': 'channels_last', 'kernel_constraint': None, 'strides': (1, 1), 'dilation_rate': (1, 1), 'kernel_regularizer': None, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'use_bias': True, 'activity_regularizer': None, 'kernel_size': (3, 3)} \n",
      "\n",
      "--> Layer 14 \n",
      "\n",
      "{'padding': 'same', 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'distribution': 'uniform', 'scale': 1.0, 'seed': None, 'mode': 'fan_avg'}}, 'name': 'block4_conv3', 'bias_regularizer': None, 'filters': 512, 'bias_constraint': None, 'activation': 'relu', 'trainable': True, 'data_format': 'channels_last', 'kernel_constraint': None, 'strides': (1, 1), 'dilation_rate': (1, 1), 'kernel_regularizer': None, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'use_bias': True, 'activity_regularizer': None, 'kernel_size': (3, 3)} \n",
      "\n",
      "--> Layer 15 \n",
      "\n",
      "{'name': 'block4_pool', 'trainable': True, 'data_format': 'channels_last', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2)} \n",
      "\n",
      "--> Layer 16 \n",
      "\n",
      "{'padding': 'same', 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'distribution': 'uniform', 'scale': 1.0, 'seed': None, 'mode': 'fan_avg'}}, 'name': 'block5_conv1', 'bias_regularizer': None, 'filters': 512, 'bias_constraint': None, 'activation': 'relu', 'trainable': True, 'data_format': 'channels_last', 'kernel_constraint': None, 'strides': (1, 1), 'dilation_rate': (1, 1), 'kernel_regularizer': None, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'use_bias': True, 'activity_regularizer': None, 'kernel_size': (3, 3)} \n",
      "\n",
      "--> Layer 17 \n",
      "\n",
      "{'padding': 'same', 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'distribution': 'uniform', 'scale': 1.0, 'seed': None, 'mode': 'fan_avg'}}, 'name': 'block5_conv2', 'bias_regularizer': None, 'filters': 512, 'bias_constraint': None, 'activation': 'relu', 'trainable': True, 'data_format': 'channels_last', 'kernel_constraint': None, 'strides': (1, 1), 'dilation_rate': (1, 1), 'kernel_regularizer': None, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'use_bias': True, 'activity_regularizer': None, 'kernel_size': (3, 3)} \n",
      "\n",
      "--> Layer 18 \n",
      "\n",
      "{'padding': 'same', 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'distribution': 'uniform', 'scale': 1.0, 'seed': None, 'mode': 'fan_avg'}}, 'name': 'block5_conv3', 'bias_regularizer': None, 'filters': 512, 'bias_constraint': None, 'activation': 'relu', 'trainable': True, 'data_format': 'channels_last', 'kernel_constraint': None, 'strides': (1, 1), 'dilation_rate': (1, 1), 'kernel_regularizer': None, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'use_bias': True, 'activity_regularizer': None, 'kernel_size': (3, 3)} \n",
      "\n",
      "--> Layer 19 \n",
      "\n",
      "{'name': 'block5_pool', 'trainable': True, 'data_format': 'channels_last', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2)} \n",
      "\n",
      "--> Layer 20 \n",
      "\n",
      "{'trainable': True, 'name': 'flatten'} \n",
      "\n",
      "--> Layer 21 \n",
      "\n",
      "{'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'distribution': 'uniform', 'scale': 1.0, 'seed': None, 'mode': 'fan_avg'}}, 'name': 'fc1', 'kernel_constraint': None, 'bias_regularizer': None, 'bias_constraint': None, 'activation': 'relu', 'trainable': True, 'kernel_regularizer': None, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'units': 4096, 'use_bias': True, 'activity_regularizer': None} \n",
      "\n",
      "--> Layer 22 \n",
      "\n",
      "{'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'distribution': 'uniform', 'scale': 1.0, 'seed': None, 'mode': 'fan_avg'}}, 'name': 'fc2', 'kernel_constraint': None, 'bias_regularizer': None, 'bias_constraint': None, 'activation': 'relu', 'trainable': True, 'kernel_regularizer': None, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'units': 4096, 'use_bias': True, 'activity_regularizer': None} \n",
      "\n",
      "--> Layer 23 \n",
      "\n",
      "{'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'distribution': 'uniform', 'scale': 1.0, 'seed': None, 'mode': 'fan_avg'}}, 'name': 'predictions', 'kernel_constraint': None, 'bias_regularizer': None, 'bias_constraint': None, 'activation': 'softmax', 'trainable': True, 'kernel_regularizer': None, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'units': 1000, 'use_bias': True, 'activity_regularizer': None} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model layers \n",
    "layers = vgg_model.layers\n",
    "for i in range(len(layers)):\n",
    "    print \"--> Layer {}\".format(i+1), \"\\n\"\n",
    "    print layers[i].get_config(), \"\\n\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fc7 layer is the layer 22, which name is fc2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'distribution': 'uniform', 'scale': 1.0, 'seed': None, 'mode': 'fan_avg'}}, 'name': 'fc2', 'kernel_constraint': None, 'bias_regularizer': None, 'bias_constraint': None, 'activation': 'relu', 'trainable': True, 'kernel_regularizer': None, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'units': 4096, 'use_bias': True, 'activity_regularizer': None}\n",
      "fc2\n"
     ]
    }
   ],
   "source": [
    "# fc7 layer\n",
    "fc7_layer = layers[21]\n",
    "print fc7_layer.get_config()\n",
    "fc7_layer_name = fc7_layer.get_config()[\"name\"]\n",
    "print fc7_layer_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (None, 4096)\n",
      "Ouput shape: (None, 4096)\n"
     ]
    }
   ],
   "source": [
    "# Input shape and output shape of the fc7 layer\n",
    "print \"Input shape:\", fc7_layer.input_shape\n",
    "print \"Ouput shape:\", fc7_layer.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights shape: (4096L, 4096L)\n",
      "Bias shape: (4096L,)\n"
     ]
    }
   ],
   "source": [
    "# Weights of the fc7 layer\n",
    "# Weights shape\n",
    "print \"Weights shape:\", fc7_layer.get_weights()[0].shape\n",
    "# Bias shape\n",
    "print \"Bias shape:\", fc7_layer.get_weights()[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get a Layer by its name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu',\n",
       " 'activity_regularizer': None,\n",
       " 'bias_constraint': None,\n",
       " 'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       " 'bias_regularizer': None,\n",
       " 'kernel_constraint': None,\n",
       " 'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "  'config': {'distribution': 'uniform',\n",
       "   'mode': 'fan_avg',\n",
       "   'scale': 1.0,\n",
       "   'seed': None}},\n",
       " 'kernel_regularizer': None,\n",
       " 'name': 'fc2',\n",
       " 'trainable': True,\n",
       " 'units': 4096,\n",
       " 'use_bias': True}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fc7 layer\n",
    "fc7_layer = vgg_model.get_layer(fc7_layer_name)\n",
    "fc7_layer.get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding of COCO images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataDir = r\"C:\\Users\\Nasser Benab\\Documents\\git\\data\\vqa\"\n",
    "dataType = \"mscoco\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ids = [(9, \"train2014\"), (25, \"train2014\")]\n",
    "# List to store the arrays for images\n",
    "imgs = []\n",
    "for image_id in image_ids:\n",
    "    # Resize the images as VGG inputs\n",
    "    img = image.load_img(os.path.join(img_dir(dataDir, dataType, \n",
    "        image_id[1]), img_file(image_id[1], image_id[0])), target_size=(224, 224)) \n",
    "    img = image.img_to_array(img)\n",
    "    imgs.append(img)\n",
    "imgs = np.stack(imgs)\n",
    "# Preprocess the images corresponding to VGG\n",
    "imgs = preprocess_input(imgs)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2L, 224L, 224L, 3L)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Submodel\" of VGG until the fc7 layer\n",
    "vgg_model_fc7 = Model(inputs=vgg_model.input, outputs=vgg_model.get_layer(\"fc2\").output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2L, 4096L)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Images embedding using the fc7 layer of VGG16\n",
    "vgg_model_fc7.predict(imgs).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM + VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lstm_vgg import LSTMVGG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare text data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataDir = r\"C:\\Users\\Nasser Benab\\Documents\\git\\data\\vqa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nasser Benab\\Documents\\git\\data\\vqa\\Annotations\\mscoco_train2014_annotations.json\n",
      "--> train2014\n",
      "loading VQA annotations and questions into memory...\n",
      "0:00:13.028000\n",
      "creating index...\n",
      "index created!\n",
      "loading VQA annotations and questions into memory...\n",
      "0:00:06.845000\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "text_vision = LSTMVGG(dataDir, n_train=300, n_test=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tokenize questions using the vocabulary of the training questions\n",
    "train_sequences, test_sequences = text_vision.tokenize_questions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 300)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of questions in the train and test set\n",
    "len(train_sequences), len(test_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Maximum length for the input questions\n",
    "input_length = 22\n",
    "\n",
    "# Vocabulary size from the training set\n",
    "V = 13666\n",
    "input_dim = V + 1\n",
    "\n",
    "# Dimension of the vectors (from the paper)\n",
    "embedding_dim = 300\n",
    "\n",
    "# The output from the embedding layer is equal to input_length x embedding_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 96.99it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 93.98it/s]\n"
     ]
    }
   ],
   "source": [
    "train_images, test_images = text_vision.process_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300L, 224L, 224L, 3L)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'answer_type': u'other',\n",
       " u'answers': [{u'answer': u'oval',\n",
       "   u'answer_confidence': u'yes',\n",
       "   u'answer_id': 1},\n",
       "  {u'answer': u'semi circle', u'answer_confidence': u'yes', u'answer_id': 2},\n",
       "  {u'answer': u'curved', u'answer_confidence': u'yes', u'answer_id': 3},\n",
       "  {u'answer': u'curved', u'answer_confidence': u'yes', u'answer_id': 4},\n",
       "  {u'answer': u'double curve', u'answer_confidence': u'yes', u'answer_id': 5},\n",
       "  {u'answer': u'banana', u'answer_confidence': u'maybe', u'answer_id': 6},\n",
       "  {u'answer': u'curved', u'answer_confidence': u'yes', u'answer_id': 7},\n",
       "  {u'answer': u'wavy', u'answer_confidence': u'yes', u'answer_id': 8},\n",
       "  {u'answer': u'twisting', u'answer_confidence': u'no', u'answer_id': 9},\n",
       "  {u'answer': u'curved', u'answer_confidence': u'maybe', u'answer_id': 10}],\n",
       " u'image_id': 487025,\n",
       " u'multiple_choice_answer': u'curved',\n",
       " u'question_id': 4870250,\n",
       " u'question_type': u'what'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vision.vqa_train2014.dataset[\"annotations\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's get a tensor with the output of our vision model\n",
    "image_input = Input(shape=(224, 224, 3))\n",
    "# Freeze the vision model weights\n",
    "vgg_model_fc7.trainable = False\n",
    "fc7 = vgg_model_fc7(image_input)\n",
    "\n",
    "# Turn the 4096 embedding from the fc7 layer to a 1024 embedding in order to \n",
    "# match the questions embedding\n",
    "encoded_image = Dense(1024, activation=\"tanh\")(fc7)\n",
    "\n",
    "# Langage model\n",
    "question_input = Input(shape=(100,), dtype='int32')\n",
    "embedded_question = Embedding(input_dim=input_dim, output_dim=embedding_dim, \n",
    "                              input_length=input_length)(question_input)\n",
    "encoded_question = LSTM(1024)(embedded_question)\n",
    "\n",
    "# Point-wise multiplication of the outputs from the vision model and the \n",
    "# langage model\n",
    "merge = multiply([encoded_question, encoded_image])\n",
    "\n",
    "# Hidden layers with 0.5 dropouts\n",
    "merge = Dropout(0.5)(merge)\n",
    "hidden1 = Dense(1000, activation=\"tanh\")(merge)\n",
    "hidden1 = Dropout(0.5)(hidden1)\n",
    "hidden2 = Dense(1000, activation=\"tanh\")(hidden1)\n",
    "\n",
    "# Final softmax layer\n",
    "output = Dense(1000, activation='softmax')(hidden2)\n",
    "\n",
    "# This is our final model:\n",
    "vqa_model = Model(inputs=[image_input, question_input], outputs=output)\n",
    "\n",
    "# Summarize layers\n",
    "print(vqa_model.summary())\n",
    "# Plot graph\n",
    "plot_model(model, to_file=\"vision_model.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
